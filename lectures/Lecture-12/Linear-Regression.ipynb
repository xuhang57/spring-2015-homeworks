{
 "metadata": {
  "name": "",
  "signature": "sha256:4694e57aad0c208b5486a35fb120af9db1b3d16b668e5ebe76c6ee7a4f51e30e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Linear Regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "\n",
      "import scipy as sp\n",
      "import scipy.sparse.linalg as linalg\n",
      "import scipy.cluster.hierarchy as hr\n",
      "from scipy.spatial.distance import pdist, squareform\n",
      "\n",
      "import sklearn.datasets as datasets\n",
      "import sklearn.metrics as metrics\n",
      "import sklearn.utils as utils\n",
      "import sklearn.linear_model as linear_model\n",
      "import sklearn.cross_validation as cross_validation\n",
      "import sklearn.cluster as cluster\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "import statsmodels.api as sm\n",
      "\n",
      "from patsy import dmatrices\n",
      "\n",
      "import seaborn as sns\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Basics on Linear Regression"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "The Linear Regression Model "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "$$Y = \\alpha +\\beta X +\\epsilon$$\n",
      "    \n",
      "We **know**: $X$ and $Y$\n",
      "\n",
      "We **do not know **: $\\alpha$, $\\beta$ and $\\epsilon$\n",
      "\n",
      "**Goal:** Given $X$ and $Y$ produce estimates of $\\alpha$ and $\\beta$ denoted by $\\widehat{\\alpha}$ and $\\widehat{\\beta}$ \n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Input/output"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Input data comes in the form of pairs $\\left(X_i,Y_i\\right)$  for $i=1,\\ldots ,n$\n",
      "\n",
      "The **true regression line **: For **every** individual it should hold that:\n",
      "$$Y_i = \\alpha +\\beta X_i +\\epsilon_i$$\n",
      "\n",
      "\n",
      "**Error** for the $i$-th data point is: $$ \\epsilon_i = Y_i-\\alpha-\\beta X_i $$\n",
      "\n",
      "\n",
      "The **estimated regression line ** : $$\\widehat{Y_i}=\\widehat{\\alpha}+\\widehat{\\beta}X_i$$\n",
      "\n",
      "\n",
      "**Residuals** measure distance between each observation from the estimated regression line and are defined as follows: $$\\widehat{\\epsilon_i} = Y_i-\\widehat{Y_i}$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Ordinary Least Squares Regression as an optimization problem"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Question**: How do we find $\\widehat{\\alpha}$ and $\\widehat{\\beta}$?\n",
      "\n",
      "**Answer**: By minimizing the residuals, or *sum of squared residuals* :\n",
      "\n",
      "\\begin{eqnarray}\n",
      "\\text{SSR} & = & \\sum_{i=1}^n \\widehat{\\epsilon_i}^2 \\\\\n",
      "& = & \\sum_{i=1}^n \\left(Y_i-\\widehat{Y_i}\\right)^2\n",
      "\\end{eqnarray}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\alpha,\\beta$ are called **regression coefficients**\n",
      "\n",
      "$\\widehat{\\alpha},\\widehat{\\beta}$ are called ** OLS (Ordinary Least Squares} regression coefficients**\n",
      "\n",
      "$\\alpha$ (or $\\widehat{\\alpha}$) is not so interesting\n",
      "\n",
      "$\\beta$ (or $\\widehat{\\beta}$) is more interesting as it shows the change in $Y$ that can be caused by a unit of change in $X$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Measuring the fit of a regression model and $R^2$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most common measure of fit is referred to as $R^2$\n",
      "\n",
      "$R^2$ measures the variability of $Y$ that can be explained by $X$\n",
      "\n",
      "Derivation:\n",
      "    $$\\text{Var}(Y) =\\frac{\\sum_{i=1}^n \\left(Y_i-\\overline{Y}\\right)}{n-1} $$\n",
      "where:\n",
      "$\\overline{Y}=\\frac{1}{n}\\sum_{i=1}^nY_i$\n",
      "\n",
      "Total Sum of Squares (TSS) is:\n",
      "\n",
      "$$\\text{TSS} = \\sum_{i=1}^n\\left(Y_i-\\overline{Y}\\right)^2 $$\n",
      "\n",
      "\n",
      "Now we can show that:\n",
      "\n",
      "$$\\text{TSS} = \\text{SSR} + \\text{RSS},$$\n",
      "\n",
      "where Sum of Squares Residuals (SSR) is:\n",
      "$$\\text{SSR} = \\sum_{i=1}^n \\left(Y_i-\\widehat{Y_i}\\right)^2,$$\n",
      "\n",
      "and Regresion Sum of Squares (RSS) is:\n",
      "\n",
      "$$\\text{RSS} = \\sum_{i=1}^n \\left(\\widehat{Y_i}-\\overline{Y}\\right)^2,$$\n",
      "\n",
      "\n",
      "Variability in $Y$ can be due to explained (RSS) and unexplained parts (SSR).\n",
      "\n",
      "\n",
      "Measure of fit $R^2$:\n",
      "\n",
      "\\begin{eqnarray}\n",
      "R^2 & = & \\frac{\\text{RSS}}{\\text{TSS}} = 1-\\frac{\\text{SSR}}{\\text{TSS}}\n",
      "\\end{eqnarray}\n",
      "\n",
      "\n",
      "$0\\leq R^2\\leq 1$; the closer the value of $R^2$ is to $1$ the better the fit of the regression; small values of SSR imply that the residuals are small and therefore we have a better fit."
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "How accurate are the estimates $\\widehat{\\alpha}$ and $\\widehat{\\beta}$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "95% Confidence interval $[x,y]$ for $\\widehat{\\alpha}$: We are 95% certain that $\\alpha$ lies in $[x,y]$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Example - I"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate a dataset using the **datasets.makeregression( )** function\n",
      "\n",
      "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = datasets.make_regression(n_samples=100, n_features=1, bias=0.1, noise=30, random_state=1)\n",
      "print X.shape, y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(X, y, c=\"slategray\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = sm.OLS(y, X)\n",
      "results = model.fit()\n",
      "print results.summary()\n",
      "print \"Confidence Intervals:\", results.conf_int()\n",
      "print \"Parameters:\", results.params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A more detailed explanation of the results can be found here:\n",
      "http://connor-johnson.com/2014/02/18/linear-regression-with-python/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(X,y, c=\"slategray\")\n",
      "plt.plot(X,results.predict(X), c='seagreen', alpha=0.8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Multidimensional data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Input **: $(Y,X_1,X_2,\\ldots , X_k)$\n",
      "\n",
      "$Y_i = \\alpha +\\beta_1X_1+\\beta_2X_2+\\ldots  + \\beta_k X_k$\n",
      "\n",
      "**Output **: Estimates $\\widehat{\\alpha},\\widehat{\\beta_i}$ for $i=1\\ldots k$ that minimize\n",
      "\n",
      "$\\text{SSR} = \\sum_{i=1}^n\\left(\\widehat{Y_i} - \\widehat{\\alpha} -\\widehat{\\beta_1}X_1-\\widehat{\\beta_2}X_2-\\ldots - \\widehat{\\beta_k} X_k\\right)^2$\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Example - II"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use again the **datasets.makeregression( )** function\n",
      "\n",
      "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = datasets.make_regression(n_samples=100, n_features=20, n_informative=5, bias=0.1, noise=30, random_state=1)\n",
      "print X.shape, y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = sm.OLS(y, X)\n",
      "results = model.fit()\n",
      "print results.summary()\n",
      "print \"Confidence Intervals:\", results.conf_int()\n",
      "print \"Parameters:\", results.params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analyzing CA housing dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ca = datasets.fetch_california_housing();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(ca)\n",
      "print type(ca.data)\n",
      "X = ca.data\n",
      "print X.shape\n",
      "print ca.feature_names\n",
      "print ca.keys()\n",
      "print ca.target\n",
      "y = ca.target;\n",
      "print y.shape\n",
      "plt.scatter(range(len(y)), y, c=\"slategray\", alpha=0.3, linewidths=0.2)\n",
      "print ca.values()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = utils.shuffle(X, y, random_state=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Split the data into training and testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "print(X_train.shape), y_train.shape\n",
      "print(X_test.shape), y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subX_train = X_train[:,0]\n",
      "subX_test = X_test[:,0]\n",
      "plt.scatter(subX_train, y_train, c=\"slategray\", alpha=0.4, linewidths=0.3)\n",
      "# plt.scatter(subX_test, y_test, c=\"seagreen\", alpha=0.2, linewidths=0.3)\n",
      "plt.xlabel('Data')\n",
      "plt.ylabel('Target');\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axes = plt.subplots(2,4,figsize=(15,10))\n",
      "\n",
      "for i in range(8):\n",
      "    plt_i = i // 4\n",
      "    plt_j = i % 4\n",
      "    subX_train = X_train[:,i]\n",
      "    # plt.subplot(2, 4, 1 + i)\n",
      "    axes[plt_i][plt_j].scatter(subX_train, y_train, c=\"slategray\", alpha=0.4, linewidths=0.3)\n",
      "    #plt.scatter(subX_test, y_test)\n",
      "    axes[plt_i][plt_j].set_xlabel('Data')\n",
      "    axes[plt_i][plt_j].set_ylabel('Target'); "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr = linear_model.LinearRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_train.shape\n",
      "regr.fit(X_train, y_train);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The coefficients and the bias are now computed"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The mean square error\n",
      "print(\"Training error: \", metrics.mean_squared_error(regr.predict(X_train),y_train))\n",
      "print(\"Test     error: \", metrics.mean_squared_error(regr.predict(X_test),y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "The score( ) function of python's LinearRegression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Returns the coefficient of determination R^2 of the prediction.\n",
      "\n",
      "The coefficient $R^2$ is defined as $(1 - u/v)$, where u is the regression sum of squares ((y_true - y_pred)^2).sum( ) and v is the residual sum of squares ((y_true - y_true.mean( ))^2).sum( ). Best possible score is 1.0, lower values are worse."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_score = regr.score(X_train,y_train)\n",
      "test_score = regr.score(X_test,y_test)\n",
      "print(\"Training score: \", train_score)\n",
      "print(\"Test     score: \", test_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coefficients = regr.coef_\n",
      "for i in range(len(coefficients)):\n",
      "    print ca.feature_names[i],\"\\t\",coefficients[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pd.DataFrame(zip(ca.feature_names, np.transpose(coefficients)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr = linear_model.LinearRegression()\n",
      "scores = cross_validation.cross_val_score(regr, X, y, cv=5)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Regression score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Visualizing the results of linear regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subX_train = X_train[:,0]\n",
      "subX_test = X_test[:,0]\n",
      "plt.scatter(subX_train, y_train, c=\"slategray\", alpha=0.4, linewidths=0.3)\n",
      "plt.plot(subX_train, coefficients[0]*subX_train, color='seagreen', linewidth=3, alpha=.8);\n",
      "plt.xlabel('Data')\n",
      "plt.ylabel('Target');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Food for thought: Analyzing Boston housing dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "boston = datasets.load_boston()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print boston.data.shape\n",
      "print type(boston.data)\n",
      "X = boston.data\n",
      "print X.shape\n",
      "print boston.feature_names\n",
      "print boston.target\n",
      "y = boston.target;\n",
      "print y.shape\n",
      "plt.scatter(range(len(y)), y, c=\"slategray\", alpha=0.4, linewidths=0.3)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = utils.shuffle(X, y, random_state=1)\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
      "print(X_train.shape), y_train.shape\n",
      "print(X_test.shape), y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr = linear_model.LinearRegression()\n",
      "print X_train.shape\n",
      "regr.fit(X_train, y_train);\n",
      "# The mean square error\n",
      "print(\"Training error: \", np.mean((regr.predict(X_train) - y_train) ** 2))\n",
      "print(\"Test     error: \", np.mean((regr.predict(X_test) - y_test) ** 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_score = regr.score(X_train,y_train)\n",
      "test_score = regr.score(X_test,y_test)\n",
      "print(\"Training score: \", train_score)\n",
      "print(\"Test     score: \", test_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coefficients = regr.coef_\n",
      "for i in range(len(coefficients)):\n",
      "    print boston.feature_names[i],\"\\t\",coefficients[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Code for setting the style of the notebook\n",
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"../theme/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<link href='http://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
        "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    .code_cell {\n",
        "        width: 105ex !important ;\n",
        "        margin-bottom: 15px !important;\n",
        "    }\n",
        "    div.cell {\n",
        "        margin-left: auto;\n",
        "        margin-right: auto;\n",
        "        width: 70%;\n",
        "    }    \n",
        "    div.cell.selected {\n",
        "        border: thin rgba(171, 171, 171, 0.5) dashed;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\n",
        "    h2 {\n",
        "        font-family: 'EB Garamond', serif;\n",
        "    }\n",
        "    h3 {\n",
        "        font-family: 'EB Garamond', serif;\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "    }\n",
        "    h4 {\n",
        "        font-family: 'EB Garamond', serif;\n",
        "    }\n",
        "    h5 {\n",
        "        font-family: 'Alegreya Sans', sans-serif;\n",
        "    }\n",
        "    div.text_cell_render {\n",
        "        font-family: 'EB Garamond',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 140%;\n",
        "    }\n",
        "    div.input_area {\n",
        "        border-color: rgba(0,0,0,0.10) !important;\n",
        "        background: #fafafa;\n",
        "    }\n",
        "    .CodeMirror {\n",
        "            font-family: \"Source Code Pro\";\n",
        "            font-size: 90%;\n",
        "    }\n",
        "    .prompt {\n",
        "        display: None;\n",
        "    }\n",
        "    .output {\n",
        "        padding-left: 50px;\n",
        "        padding-top: 5px;\n",
        "    }\n",
        "    .output_wrapper {\n",
        "        padding-left: 5px;\n",
        "        padding-top: inherit;\n",
        "    }\n",
        "    div.output_scroll {\n",
        "        width: inherit;\n",
        "    }\n",
        "    .inner_cell {\n",
        "        padding-left: 5px;\n",
        "    }\n",
        "    .text_cell_render h1 {\n",
        "        font-weight: 200;\n",
        "        font-size: 50pt;\n",
        "        line-height: 100%;\n",
        "        color:#CD2305;\n",
        "        margin-bottom: 0.5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #CD2305;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    .warning {\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }  \n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x39b9dd8>"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}